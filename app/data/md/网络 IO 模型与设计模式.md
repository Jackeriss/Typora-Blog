## 网络 I/O 模型与设计模式

Redis 为什么这么快？

Kafka 为什么这么快？

Nginx 为什么这么快？

Node.js 为什么这么快？

Netty 为什么这么快？

……

虽然这些以快著称的中间件和框架在网络 I/O 的实现细节上各有千秋，但是也有一些共同点，那就是在上层通过 Reactor 设计模式充分利用了操作系统底层的 I/O 多路复用模型，使之发挥出了应有的效果。那么什么是 I/O 多路复用模型？什么又是 Reactor 设计模式？我们先从操作系统下五种常见的网络 I/O 模型说起。

### 网络 I/O 模型

在了解网络 I/O 模型之前，我们首先需要明确几个概念：

#### 如何判断 I/O 操作是否阻塞？

在操作系统中，判断一个操作是否是阻塞操作很简单，其实就是看这个操作是否会使得进程转变为等待状态。

#### 什么是同步 I/O 和异步 I/O ？

按照 POSIX 的定义，如果一个 I/O 模型会导致请求进程阻塞，那它就是同步 I/O，否则就是异步 I/O。

下面我就通过《UNIX网络编程卷1》中几张经典的图片来分别介绍一下这五种 I/O 模型：

#### 阻塞 I/O（Blocking I/O）

![image-20200924212200643](https://i.loli.net/2020/09/24/E6oNh81GMqeUOl3.png)

在阻塞 I/O 模型中一个线程监听一个文件描述符，在数据准备好并且从内核态复制到用户态之后才会返回，例如 Linux 下使用阻塞的文件描述符。

#### 非阻塞 I/O（Non-blocking I/O）

![image-20200924221307094](https://i.loli.net/2020/09/24/5UbMymzVoacrgAi.png)

在非阻塞 I/O 模型中一个线程监听一个文件描述符，在数据准备好之前会返回错误，用户需要不断的尝试，如果数据准备好了则会将数据从内核态复制到用户态然后再返回，例如 Linux 下通过设置 SOCK_NONBLOCK 标记创建非阻塞的文件描述符。

#### I/O 多路复用（I/O Mutiplexing）

![image-20200924221543024](https://i.loli.net/2020/09/24/fdnHAGK5bPxXZt4.png)

一个线程监听多个文件描述符，请求进程会阻塞在 select / poll / epoll 等系统调用上，而不是阻塞在真正的 I/O 系统调用上。

#### 信号驱动 I/O（Signal-driven I/O）

![image-20200924222515114](/Users/Jackeriss/Library/Application%20Support/typora-user-images/image-20200924222515114.png)

除了 I/O 多路复用方式通知 I/O 事件，还可以通过 SIGIO 信号来通知 I/O 事件。两者不同的是，在等待数据达到期间，I/O 多路复用会阻塞应用进程，而 SIGIO 方式则不会。

#### 异步 I/O（Asynchronous I/O）

![image-20200924222553652](https://i.loli.net/2020/09/24/eyTOUQhDwYXRB39.png)

用户进程在调用后无需任何等待，系统在数据准备好后会将直接将数据从内核态复制到用户态，然后会回调用户进程，例如 Windows 下的 IOCP。

#### I/O 模型对比

![image-20200924222814471](https://i.loli.net/2020/09/24/ExRZDtcf1hqU8ST.png)

简单总结一下就是除了异步 I/O 以外的四种 I/O 模型都是同步 I/O，因为它们都会阻塞调用进程。而在这四种模型里，除了同步 I/O 是同步阻塞外，其余三种都是同步非阻塞，因为系统内真正的 I/O 调用是非阻塞的。

### 网络 I/O 设计模式

我们的程序要如何设计才与这些 I/O 模型配合，正确的处理各种 I/O 事件呢？

#### Reactor 模式

我们通常使用 Reactor 模式来处理同步 I/O，其核心是将关注的 I/O 事件注册到多路复用器上，一旦有 I/O 事件触发，将事件分发到事件处理器中，执行就绪 I/O 事件对应的处理函数中。

Reactor 模式找那个有三个重要的组件：

**多路复用器**：由操作系统提供接口

**事件分离器**：将多路复用器返回的就绪事件分发到事件处理器中

**事件处理器**：就绪事件处理函数

Reactor 模式的大概流程如下：

![image-20200924230857090](https://i.loli.net/2020/09/24/rktDzv4AqZPEuCJ.png)

1. 注册 I/O 就绪事件处理器
2. 事件分离器等待 I/O 就绪事件
3. I/O 事件触发，激活事件分离器，分离器调度对应的事件处理器
4. 事件处理器完成 I/O 操作，处理数据

#### Proactor 模式

与 Reactor 模式不同的是，Proactor 使用异步 I/O 系统接口将 I/O 操作托管给操作系统，Proactor 模型中分发处理异步 I/O 完成事件，并调用相应的事件处理接口来处理业务逻辑。

Proactor 模式流程如下：

![image-20200924234116673](https://i.loli.net/2020/09/24/vRgGyWEicxPT8sF.png)



1. 发起 I/O 异步操作，注册 I/O 完成事件处理器
2. 事件分离器等待 I/O 操作完成事件
3. 内核并行执行实际的 I/O 操作，并将结果数据存入用户自定义缓 冲区
4. 内核完成 I/O 操作，通知事件分离器，事件分离器调度对应的事件处理器
5. 事件处理器处理用户自定义缓冲区中的数据

### 并发模式

在 I/O 密集型的程序，采用并发方式可以提高 CPU 的使用率，可采用多进程和多线程两种方式实现并发。

首先区分一个概念，并发模式中的“同步”、“异步”与 I/O 模型中的“同步”、“异步”是两个不同的概念：

**并发模式中**，“同步”指程序按照代码顺序执行，“异步”指程序依赖事件驱动。

**I/O模型中**，“同步”、“异步”用来区分 I/O 操作的方式，是主动通过 I/O 操作拿到结果，还是由内核异步的返回操作结果。

同步读流程：

![image-20200924234856488](https://i.loli.net/2020/09/24/P8ZyXohOMbrKGWD.png)

异步读流程：

![image-20200924234912365](https://i.loli.net/2020/09/24/Q1PtX6AYsof4lIm.png)

#### 半同步 / 半异步模式

![image-20200924235042452](https://i.loli.net/2020/09/24/mcEn7wqITHUtp54.png)

其中异步线程处理 I/O 事件，同步线程处理请求对象，简单的来说：

1. 异步线程监听到事件后，将其封装为请求对象插入到请求队列中
2. 请求队列有新的请求对象，通知同步线程获取请求对象
3. 同步线程处理请求对象，实现业务逻辑

#### 半同步/半反应堆模式



#### 一种高效的演变模式



####  Follower/Leader 模式



### 改善性能的方法

#### 数据复制

如果应用程序不关心数据的内容，就没有必要将数据拷贝到应用缓冲区，可以借助内核接口直接将数据拷贝到内核缓冲区处理，如在提供文件下载服务时，不需要将文件内容先读到应用缓冲区，在调用 send 接口发送出去，可以直接使用 sendfile （零拷贝）接口直接发送出去。

#### 资源池

在服务运行期间，需要使用系统调用为用户分配资源，通常系统资源的分配都是比较耗时的，如动态创建进程／线程。可以考虑在服务启动时预先分配资源，即创建资源池，当需要资源，从资源池中获取即可，若资源池不够用时，再动态的分配，使用完成后交还到资源池中。这实际上是用空间换取时间，在服务运行期间可以节省非必要的资源创建过程。需要注意的是，使用资源池还需要根据业务和硬件环境对资源池的大小进行限制。

资源池是一个抽象的概念，常见的包括进程池、线程池、 内存池、连接池等，这里就不一一介绍了。

#### 锁

对共享资源的操作是并发程序中经常被提起的一个话题，都知道在业务逻辑上无法保证同步操作共享资源时，需要对共享资源加锁保护，但是锁不仅不能处理任何业务逻辑，而且还存在一定的系统开销。并且对锁的不恰当使用，可能成为服务期性能的瓶颈。

针对锁的使用有如下建议：

1. 如果能够在设计层面避免共享资源竞争，就可以避免锁，如上述半同步／半反应堆模式的演变模式
2. 若无法避免对共享资源的竞争，优先考虑使用无锁队列的方式实现共享资源
3. 使用锁时，优先考虑使用读写锁；此外，锁的范围也要考虑，尽量较少锁的颗粒度，避免其他线程无谓的等待

#### 上下文切换

并发程序需要考虑上下文切换的问题，内核调度线程（进程）执行是存在系统开销的，若线程（进程）调度占用 CPU 的时间比重过大，那处理业务逻辑占用的 CPU 时间就会不足。在项目中，线程（进程）数量越多，上下文切换会很频繁，因此是不建议为每个用户连接创建一个线程，一个线程可同时处理多个用户连接，是比较合理的解决方案。

多核的机器上，并发程序的不同线程可以运行在不同的 CPU 上，只要线程数量不大于 CPU 数目，上下文切换不会有什么问题，在实际的并发网络模块中，线程（进程）的个数也是根据 CPU 数目来确定的。在多核机器上，可以设置CPU亲和性，将进程／线程与 CPU 绑定，提高 CPU cache 的命中率，建好内存访问损耗。

#### 时间轮

经常会面临一些业务定时超时的需求，用例子来说明吧。

**功能需求**：服务器需要维护来自大量客户端的TCP连接（假设单机服务器需要支持的最大TCP连接数在10W级别），如果某连接上60s内没有数据到达，就认为相应的客户端下线。

先介绍一下两种容易想到的解决方案,

**方案 a 轮询扫描**

处理过程为：

1. 维护一个map<client_id, last_update_time > 记录客户端最近一次的请求时间；
2. 当client_id对应连接有数据到达时，更新last_update_time；
3. 启动一个定时器，轮询扫描map 中client_id 对应的last_update_time，若超过 60s，则认为对应的客户端下线。

轮询扫描，只启动一个定时器，但轮询效率低，特别是服务器维护的连接数很大时，部分连接超时事件得不到及时处理。

**方案 b 多定时器触发**

处理过程为：

1. 维护一个map<client_id, last_update_time > 记录客户端最近一次的请求时间；
2. 当某client_id 对应连接有数据到达时，更新last_update_time，同时为client_id启用一个定时器，60s后触发;
3. 当client_id对应的定时器触发后，查看map中client_id对应的last_update_time是否超过60s，若超时则认为对应客户端下线。

多定时器触发，每次请求都要启动一个定时器，可以想象，消息请求非常频繁是，定时器的数量将会很庞大，消耗大量的系统资源。

**方案 c 时间轮方案**

下面介绍一下利用时间轮的方式实现的一种高效、能批量的处理方案，先说一下需要的数据结构：

1. 创建0~60的数据，构成环形队列time_wheel，current_index维护环形队列的当前游标，如图19所示；
2. 数组元素是slot 结构，slot是一个set<client_id>，构成任务集；
3. 维护一个map<client_id,index>，记录client_id 落在哪个slot上。

![img](https://i.loli.net/2020/09/24/fZFdSjxoKg7QhIi.png)

执行过程为：

1. 启用一个定时器，运行间隔1s，更新current_index，指向环形队列下一个元素，0->1->2->3...->58->59->60...0；
2. 连接上数据到达时，从map中获取client_id所在的slot，在slot的set中删除该client_id；
3. 将client_id加入到current_index - 1锁标记的slot中；
4. 更新map中client_id 的index 为current_index-1 。

**与 a、b 两种方案相比，方案 c 具有如下优势**：

1. 只需要一个定时器，运行间隔 1s，CPU 消耗非常少；
2. current_index 所标记的 slot 中的 set 不为空时，set 中的所有 client_id 对应的客户端均认为下线，即批量超时。

### 参考资料

《UNIX网络编程卷1：套接字联网API（第3版）》

[异步网络模型](https://tech.youzan.com/yi-bu-wang-luo-mo-xing/)







